{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "2020-07-25-Encoding-tabular-data-as-images.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyPj9AWRurZfpKKKACD8CTmH"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "kfR6yhVOGCrs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZrtawrGJH1HX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RcOoLHBuH6k6",
        "colab_type": "text"
      },
      "source": [
        "# \"Encoding tabular data as images\"\n",
        "> \"Trolling Kaggle. Just because.\"\n",
        "\n",
        "- toc: true\n",
        "- badges: true\n",
        "- comments: true\n",
        "- categories: [Kaggle,Titanic,DL,Tools]"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aZV3D6BzH1i9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#hide\n",
        "from IPython.display import Image as IPImage\n",
        "\n",
        "def show_image(url):\n",
        "  display(IPImage(url=url))\n",
        "\n",
        "def blog_image(fn):\n",
        "  show_image(\"https://joedockrill.github.io/blog/images/\" + fn)"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lfaOsFGHI0--",
        "colab_type": "text"
      },
      "source": [
        "**TL;DR.** I’m in the top 9% on the Titanic leaderboard using a CNN. Yes rly."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "As8vRO2iIVPu",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 190
        },
        "outputId": "e2935c9a-45a3-43b4-83db-d531687bf247"
      },
      "source": [
        "#hide_input\n",
        "blog_image(\"titanic_lb.jpg\")"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<img src=\"https://joedockrill.github.io/blog/images/titanic_lb.jpg\"/>"
            ],
            "text/plain": [
              "<IPython.core.display.Image object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VJMhoSHNJHEV",
        "colab_type": "text"
      },
      "source": [
        "I was playing with fastai.tabular (v1) the other day and I could not get it to be my friend.\n",
        "\n",
        "All the time I could hear Jeremy’s voice in the back of my head saying *“make things which aren’t pictures, into pictures”*, so I had a quick look to see if there are any papers about encoding tabular data as images. I figured that must be A Thing people are doing.\n",
        "\n",
        "I found a paper describing a method called [SuperTML](https://arxiv.org/abs/1903.06246) which is based off of something called [Super Characters](https://www.aclweb.org/anthology/W18-6245/); both essentially involve putting your non-image data (text or number values) onto an image and then using a CNN to process them."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QcEwSyOXJArD",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 222
        },
        "outputId": "d9972888-ee6c-4deb-f9b8-7790a38afecb"
      },
      "source": [
        "#hide_input\n",
        "blog_image(\"supertml.png\")"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<img src=\"https://joedockrill.github.io/blog/images/supertml.png\"/>"
            ],
            "text/plain": [
              "<IPython.core.display.Image object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MhLWz5rFJ8_1",
        "colab_type": "text"
      },
      "source": [
        "I mean, literally like that. File this under “so stupid there’s no way it should work”, but it actually does.\n",
        "\n",
        "The first thing which occured to me though is that the model is going to understand the underlying values an awful lot quicker if I just use them as color codes or greyscale values. In my limited experimenting so far this seems to be the case, and at the moment I’m generating images which look like this."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ohjOWjj5KHUD",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 222
        },
        "outputId": "a0e5aee2-a810-497c-c49c-b60f2dd6a1f9"
      },
      "source": [
        "#hide_input\n",
        "blog_image(\"df_to_image.png\")"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<img src=\"https://joedockrill.github.io/blog/images/df_to_image.png\"/>"
            ],
            "text/plain": [
              "<IPython.core.display.Image object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IsA2qzzrLbq9",
        "colab_type": "text"
      },
      "source": [
        "The second thing which occured to me is that maybe I could feature engineer the data to death, throw everything including the kitchen sink into the images and have the model figure out which features mattered. That would have been so awesome. It did **not** work.\n",
        "\n",
        "So far I’m finding simpler architectures are better for this. That’s not terribly surprising. It’s also very quick to train as there’s very little to figure out.\n",
        "\n",
        "I managed to get top 9% on Titanic using ResNet-18 (again with fastai), with an accuracy of 0.79665. That’s a PB for me (although I was very wet behind the ears when I first tried this competition). As best I can tell, the **real** record for this competition (once you get past all the 1.0 idiots) was around .85 (anything above about 80% is ok) and it involved ensembling quite a few different models. I did 5 epochs at 1e-2 and then 5 at 1e-3. I didn’t even need to unfreeze, it’s basically looking at minecraft blocks.\n",
        "\n",
        "If you want to play around with this, I’ve put the image encoder onto github.\n",
        "\n",
        "[github.com/joedockrill/DFToImageEncoder](https://github.com/joedockrill/DFToImageEncoder)\n",
        "\n",
        "The code is in the following cell. It's not complicated and there may be other directions this could go in, other information which could be encoded into the images. Drop a comment or have a play with it if you can think of anything."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DmJS1ZvGKKvy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#collapse-hide\n",
        "from PIL import Image as PImage\n",
        "from PIL import ImageDraw as PImageDraw\n",
        "import numpy as np\n",
        "from math import sqrt, ceil\n",
        "from sklearn import preprocessing\n",
        "\n",
        "class DFToImageEncoder():\n",
        "  def __init__(self):\n",
        "    self.__scaler = None\n",
        "    self.__encoders = None\n",
        "    self.__data = None\n",
        "    self.__mms_data = None\n",
        "    self.__exclude_cols = None\n",
        "\n",
        "  @property\n",
        "  def data(self):\n",
        "    return self.__data\n",
        "\n",
        "  @data.setter\n",
        "  def data(self, df):\n",
        "    self.__data = df\n",
        "    self.__mms_data = df.copy(); mms = self.__mms_data;\n",
        "    \n",
        "    # drop excluded cols\n",
        "    if(self.__exclude_cols is not None): mms.drop(self.__exclude_cols, axis=1, inplace=True)\n",
        "    # fit if we haven't already\n",
        "    if(self.__scaler is None): self.fit(mms)\n",
        "    # label encode any cat cols and scale from 0-255\n",
        "    if(self.__encoders is not None):\n",
        "      for col,enc in self.__encoders.items():\n",
        "        mms[col] = enc.transform(mms[col])\n",
        "    mms[mms.columns] = self.__scaler.transform(mms[mms.columns])\n",
        "\n",
        "  @property\n",
        "  def exclude_cols(self):\n",
        "    return self.__exclude_cols \n",
        "\n",
        "  @exclude_cols.setter\n",
        "  def exclude_cols(self, cols):\n",
        "    # cols to exclude from the image (like your target)\n",
        "    self.__exclude_cols = cols\n",
        "    if(self.data is not None): self.data = self.data\n",
        "\n",
        "  def fit(self, df):\n",
        "    # fit to all your data then process train/val/test by changing .data\n",
        "    df = df.copy()\n",
        "    if(self.__exclude_cols is not None): df.drop(self.__exclude_cols, axis=1, inplace=True)\n",
        "\n",
        "    for col in df.columns:\n",
        "      if df[col].dtype == np.object:\n",
        "        if(self.__encoders is None): self.__encoders = {}\n",
        "        enc = preprocessing.LabelEncoder().fit(df[col])\n",
        "        self.__encoders[col] = enc\n",
        "        df[col] = enc.transform(df[col]) # have to actually tfm here or the scaler can't fit\n",
        "        \n",
        "    self.__scaler = preprocessing.MinMaxScaler(feature_range=(0, 255))\n",
        "    self.__scaler.fit(df)\n",
        "\n",
        "  def iterrows(self):\n",
        "    # index and row from the original df + generated image \n",
        "    for index, row in self.__data.iterrows():\n",
        "      img = self.create_image(self.__mms_data.loc[index].values)\n",
        "      yield index, row, img\n",
        "\n",
        "  @staticmethod\n",
        "  def create_image(vals):\n",
        "    # you can call this directly with an array of 0-255 values (floats or ints, i don't care)\n",
        "    img_size = 200\n",
        "    mtx_size = ceil(sqrt(len(vals)))\n",
        "    div_size = img_size // mtx_size\n",
        "\n",
        "    img = PImage.new(\"L\", (img_size, img_size))\n",
        "    drw = PImageDraw.Draw(img)\n",
        "\n",
        "    i = 0\n",
        "    for y in range(0, mtx_size):\n",
        "      for x in range(0, mtx_size):\n",
        "        x0 = x*div_size; x1 = x0 + div_size\n",
        "        y0 = y*div_size; y1 = y0 + div_size\n",
        "        \n",
        "        if i < len(vals):\n",
        "          drw.rectangle([x0,y0,x1,y1], fill=(int(vals[i])))\n",
        "        else:\n",
        "          drw.line((x0+5,y0+5,x1-5,y1-5), fill=128, width=5)\n",
        "          drw.line((x0+5,y1-5,x1-5,y0+5), fill=128, width=5)\n",
        "          \n",
        "        i += 1\n",
        "\n",
        "    for i in range(1, mtx_size):\n",
        "      drw.line((i*div_size,0, i*div_size,img_size), fill=0)\n",
        "      drw.line((0,i*div_size, img_size,i*div_size), fill=0)\n",
        "\n",
        "    return img\n",
        "\n",
        "  @staticmethod\n",
        "  def fastai_img(img):\n",
        "    # for getting preds directly from a fastai model\n",
        "    from fastai.vision.image import Image\n",
        "    import torchvision.transforms as tfms\n",
        "    img_tensor = tfms.ToTensor()(img)\n",
        "    return Image(img_tensor)\n"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "17Qw-mYJOsxV",
        "colab_type": "text"
      },
      "source": [
        "You use it like this:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U1_UDyoPN8Ib",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# setup \n",
        "enc = DFToImageEncoder()\n",
        "enc.exclude_cols = [\"PassengerId\", \"Survived\"]\n",
        "enc.fit(df_all) # fit to ALL the data\n",
        " \n",
        "# create training images saved to disc\n",
        "enc.data = df_train\n",
        " \n",
        "for index, row, img in enc.iterrows():\n",
        "  # exclude_cols are still returned for you to inspect\n",
        "  if row.Survived == True:\n",
        "    path = \"images/Survived/\"\n",
        "  else:\n",
        "    path = \"images/Died/\"\n",
        "  img.save(path + str(row.PassengerId) + \".jpg\")\n",
        " \n",
        "# train your model...\n",
        "train_model()\n",
        " \n",
        "# get predictions, use in memory images directly\n",
        "enc.data = df_test # switch to test data\n",
        " \n",
        "for index, row, img in enc.iterrows():\n",
        "  # helper function to convert to a fastai image\n",
        "  fast_img = DFToImageEncoder.fastai_img(img)\n",
        "  pred,_,_ = learn.predict(fast_img)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}